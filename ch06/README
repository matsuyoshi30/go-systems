TCPソケットとHTTPの実装

- HTTPとその上のプロトコル
  - RPC
    リクエストボディを使って関数呼び出しのようにサーバーの機能を呼び出す
  - REST
    階層化されたリソースにアクセスすることで欲しいデータを取得
  - GraphQL
    きれいな階層構造にマッピングできない、複数の属性が考えられるデータをピンポイントで取得

- ソケット
  アプリケーション層からトランスポート層を利用するときのAPI
  サーバー側：ソケットを開いてまつ Listen()
  クライアント側：ソケットに接続して通信する Dial()

- HTTPサーバーとクライアントをGoで実装 (./http)

- 速度改善(1) HTTP1.1のKeep-Alive対応 (./keep-alive)
  HTTP1.1からはKeep-Aliveが導入され、しばらくの間はTCP接続のコネクションを使い回せるようになった
  ＝再接続のコストを削減
  サーバー側：コネクションのタイムアウト設定、レスポンスのHTTP1.1設定、ContentLength設定
  クライアント側：コネクションのタイムアウト時のリトライ処理

- 速度改善(2) 圧縮 (./gzip)
  データ量を圧縮して転送開始〜終了までの時間を短縮する
  ＝通信時間の短縮
  サーバー側：リクエストのエンコードアルゴリズムを判定して、ボディをgzip化するか判断してレスポンスを作成
  クライアント側：リクエストのヘッダーにgzip設定、レスポンスのエンコードアルゴリズムを確認してレスポンスの読み取り処理

- 速度改善(3) チャンク形式のボディー送信 (./chunks)
  とても大きいデータを転送するときに準備が完了してからじゃないとそれだけレスポンスのスタートが遅くなる
  細切れのチャンク形式にすれば準備できたものから処理できるのでトータルの時間短縮になる
  ＝レスポンスの送信開始を早める
  サーバー側：Transfer-Encoding: chunkedを設定
  クライアント側：\nごとに読み込む＝チャンクごとに読み込む

- 速度改善(4) パイプライニング (./pipelining)
  送受信を非同期化してトータルの時間を短縮する。レスポンスが返ってこなくてもどんどんリクエストを投げる
  ＝通信の多重化
  サーバー側：サーバーの状態を変更しないGETやHEADであれば、サーバー側で並列処理が可能。リクエストの順序でレスポンスを返す→チャネル内チャネルを使用！
  クライアント側：リクエストは先にどかっと送ってよい。レスポンスはまとめて受信する。
  ちなみにHTTP/2では順序の保証とか不要、サーバー側で優先順位を決めることも出来る

"最終的なアーキテクチャは結果でしかありません。そこに至る、その場その場の機能改善の意思決定こそが、ソフトウェアの設計だといえます。"
p121より抜粋